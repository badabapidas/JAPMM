Java virtual machine flags:

@@@@@@@@@@@@@@@@
-XX:+PrintCompilation // to find out what kind  of compilation is happening when the JVM is running our code 

The output can be as given below
	 81    1       3       java.lang.Object::<init> (1 bytes)
     82    2       3       java.lang.String::hashCode (55 bytes)
     82    3       3       java.lang.String::charAt (29 bytes)
     84    4       3       java.lang.String::length (6 bytes)
     86    5       3       java.lang.String::equals (81 bytes)
     88    7       3       java.lang.Math::min (11 bytes)
     89    6       3       java.lang.AbstractStringBuilder::ensureCapacityInternal (27 bytes)
     89   12     n 0       java.lang.System::arraycopy (native)   (static)
     89    8       3       java.lang.CharacterData::of (120 bytes)
     89   14       4       java.lang.String::charAt (29 bytes)
     89    9       3       java.lang.CharacterDataLatin1::getProperties (11 bytes)
     90   10       3       java.lang.Character::toLowerCase (9 bytes)
     90   11       3       java.lang.CharacterDataLatin1::toLowerCase (39 bytes)
     90   18       3       java.lang.String::indexOf (70 bytes)
     90    3       3       java.lang.String::charAt (29 bytes)   made not entrant
     90   13       3       java.lang.AbstractStringBuilder::append (29 bytes)
     91   16       3       java.io.WinNTFileSystem::isSlash (18 bytes)
     91   15       3       java.lang.StringBuilder::append (8 bytes)
     92   17  s    3       java.lang.StringBuffer::append (13 bytes)
     92   19       3       java.util.Arrays::copyOfRange (63 bytes)
     97   20       3       java.lang.System::getSecurityManager (4 bytes)
     99   21       3       java.lang.String::getChars (62 bytes)
     99   22       1       java.lang.Integer::intValue (5 bytes)
     99   23       1       java.lang.Boolean::booleanValue (5 bytes)
    100   24       3       com.bada.example1.PrimeNumbers::isPrime (35 bytes)
    100   26       3       java.lang.Number::<init> (5 bytes)
    100   27       3       java.lang.Integer::<init> (10 bytes)
    100   25       3       java.lang.Integer::valueOf (32 bytes)
    100   29 %     4       com.bada.example1.PrimeNumbers::isPrime @ 5 (35 bytes)
    101   28       1       java.util.ArrayList::size (5 bytes)
    101   30       3       java.util.ArrayList::add (29 bytes)
    101   31       3       java.util.ArrayList::ensureCapacityInternal (13 bytes)
    103   32       3       com.bada.example1.PrimeNumbers::getNextPrimeAbove (36 bytes)
    104   32       3       com.bada.example1.PrimeNumbers::getNextPrimeAbove (36 bytes)   made not entrant
    105   33       3       com.bada.example1.PrimeNumbers::getNextPrimeAbove (36 bytes)
    105   34       4       com.bada.example1.PrimeNumbers::isPrime (35 bytes)
    106   24       3       com.bada.example1.PrimeNumbers::isPrime (35 bytes)   made not entrant
    162   35       4       com.bada.example1.PrimeNumbers::getNextPrimeAbove (36 bytes)
    167   33       3       com.bada.example1.PrimeNumbers::getNextPrimeAbove (36 bytes)   made not entrant
    421   37       3       java.lang.AbstractStringBuilder::append (50 bytes)
    422   45       3       java.lang.Integer::getChars (131 bytes)
    422   49       1       java.lang.Object::<init> (1 bytes)
    422    1       3       java.lang.Object::<init> (1 bytes)   made not entrant
    422   42       3       java.lang.Integer::stringSize (21 bytes)
    422   36       1       java.util.ArrayList::access$000 (5 bytes)
    423   46       3       java.util.ArrayList$Itr::checkForComodification (23 bytes)
    423   47       3       java.lang.Integer::toString (8 bytes)
    423   48       3       java.lang.Integer::toString (48 bytes)
    423   50       4       java.lang.StringBuilder::append (8 bytes)
    423   38       3       java.lang.StringBuilder::append (8 bytes)
    424   39       3       java.lang.String::<init> (10 bytes)
    424   40       3       java.lang.String::valueOf (14 bytes)
    424   51       4       java.lang.Integer::getChars (131 bytes)
    424   41       3       java.lang.StringBuilder::append (9 bytes)
    424   43       3       java.util.ArrayList$Itr::hasNext (20 bytes)
    425   44       3       java.util.ArrayList$Itr::next (66 bytes)
    425   52       3       sun.nio.cs.SingleByte$Encoder::encode (32 bytes)
    425   15       3       java.lang.StringBuilder::append (8 bytes)   made not entrant
	
Column 1: No of milliseconds since the virtual machine started
Column 2: Order in which the method or code block is compiled
Column 3.1: s to define the synchrounous method
Column 3.2: n to define the native method
Column 3.3: ! to define exception handling
Column 3.4: % mean the code is being natively compiled and now running on code cache; showing % means the method is now running on most optimal way possible 
Column 4: this tel us what kind of compiling has taken place(0-4)
Column 4.1: 0 means no compilation, the code is just beind interpreted
Column 4.2: 1-4 means deep level of compilation; 4 means the code is copiled in best level and the code is cacehd;
Column 5: Line of code the code actually being compiled


JVM JIT Compilers: A virtual machine has 2 built in compilers C1 and C2

C1: Native level 1, 2, 3
C2: Native level 4

Virtual machine decides which level of compilation will apply in a particular block of code based on how the native is run and how complex the time consuming it is
So if a block of code is using many no of times, JVM will use the compiler C2 so that the best possible way the code can be compiled and even the code will be cached so that it increases performance
The higher the no of compilation the more optimized the code should be.


@@@@@@@@@@@@@@@@
-XX:+UnlockDiagnosticVMOptions -XX:+LogCompilation //To store the logs in a file
 
While C2 compiler is use its use code cache to store the code block so that it can be used faster in future refs. But code cache even has some size limit. So if that size limit reached then JVM will take care of removing and again adding code blocks in the code cache based on the active usage.

But if all the stored codes are being actively using then JVM will show warning message as "CodeCache is full. Compiler hass been disabled".  This does not interrupt your running but it means the code is not running in an optimized way.

@@@@@@@@@@@@@@@@
-XX:+PrintCodeCache //to get the default size of the cache code, how much used and how much cache is free

Output: 
CodeCache: size=245760Kb used=1149Kb max_used=1160Kb free=244610Kb
 bounds [0x0000000002b00000, 0x0000000002d70000, 0x0000000011b00000]
 total_blobs=283 nmethods=52 adapters=145
 compilation: enabled
 
@@@@@@@@@@@@@@@@
-XX:ReservedCodeCacheSize=28m // to set a new cache size

New Output:
CodeCache: size=28672Kb used=1149Kb max_used=1160Kb free=27522Kb
 bounds [0x0000000002d10000, 0x0000000002f80000, 0x0000000004910000]
 total_blobs=283 nmethods=52 adapters=145
 compilation: enabled 
 
Using JCONSOLE you can see the code cache
C:\Users\bada\AppData\Local\Temp\hsperfdata_bada // location where JVM store its proceses; you have to give first the full right access to everyone

So if you use jconsole to see the code cache size of your running application then just remember jconsole is going to share some space from code cache as JVM has to do some extra work to make jconsole to connect with our application. It has some back ground process;

you can use -XX:+PrintCompilation -XX:ReservedCodeCacheSize=28m -XX:+PrintCodeCache and runn you program givng some sleep and then connect you appication using jconsole, you can see what are the back ground process JVM do for this communication.
 
 
JVM Compilers Flags
-client
-server
-d64

@@@@@@@@@@@@@@@@
-XX:-TieredCompilation // allowed to you to turned off tiered compilation. TO tell the JVM to run in interpreted mode only

@@@@@@@@@@@@@@@@
-XX:+PrintFlagsFinal // show you all the vailable flags, where on of them CICompilerCount will show you the available threads to compiling our code

Native Compilation Tuning
1. increase/decrease CICompilerCount
@@@@@@@@@@@@@@@@
-XX:CICompilerCount=n

we can use jdk inbuild tools to fine tuned this like given below
- jps // to get the runnins processes process id
- jinfo -flag CICompilerCount pid // to get the flag value using jinfo
 
2. increase/decrease Compile threashold
@@@@@@@@@@@@@@@@
-XX:CompileThreshold=n 
 
 
HOW MEMORY WORKS - THE STACK AND THE HEAP 

Threads uses stack to store its local execution status and local primitives. Individual thread use different stack. Heap is used to store sharind data objects. So primitve datas stores in stack but apart from primitives any object or custom define data will be stored in heap and the reference of that object will be stored in stack. One thread can not use the stack variables of other thread as this will be local scoped. But all the threads can acces heap stored data which healps is sharing datas among different executions in different threads.   

Final keyword should be used for better performance.

Escaping references:

Escaping reference means there is some loop whole which can be breached. So suppose there are a no of records of customer, and there is a method exposed getCustomers() which will return you the records.
Now depending on the implementation those records can e easily change. So there are couple of ways how we can restrict this
1. Istead of sending the original copy we can create a copy of that and sending
2. We can create a unmodifiable collection and sending - this will give you runtime exception if anyone try to change the details of that object
3. We can create an interface and hide the setters, this will give you the compile time error rather than runtime
4. In java 9 or above, there is a concept of expossing needed modules to outside. With this we can decide what are the classes we should expose to outside so that no body can do a trick with the impl

The Metaspace:

In JVM apart from heap and stack there is a concept of metaspace. All the metadata related to any executions like class names, method names etc is being stored here. All the static variable (primitive, objects) are stored in the metaspace. These static objects will remain foreover in the metaspace until your JVM s running. Its not like stack. And moreover this metaspace is accessible from any threads. Thats why declaring any variable static means that can be access from any class anywhere.

There is not difference between private and public variable. both the variales stored in a same way in the heap. Metaspace is there in JAVA from version 8. before that there was a concept of PermGen.

Its not always that the objects are defined in the heap only. Some object might be like this which is used by only one block of code. As a programmer we dont have the facility to chose where the objects will create so JVM is intelligent enough to take a decission in this case and create the object in the stack rather then in the heap. And once the object is no longer used it will be poped out from the stack.

In case of String if two strings have same value then virtual machine make those as a one. Its not always true in case of any assigments in Strings. Java has one method call intern to avoid this problem. It will make sure same objects are reusable. but intern is a expensive operation to perform.

JVM Memory Optimization by Tuning:
1. -XX:+PrintStringTableStatistics //the size and density of the string pool
2. -XX:StringTableSize // Tuning the size of the String Pool
3. -XX:MaxHeapSize=600m [Shortcut Keys: -Xmx] // to set the size of heap memory 
4. -XX:InitialHeapSize=1g [Shortcut Keys: -Xms] // to set the size of initial heap size 
5. -XX:+UnlockDiagnosticVMOptions -XX:+PrintFlagsFinal // to see the default values of the heap

@@@@@@@@@@@@@@@@
-XX:+PrintStringTableStatistics //the size and density of the string pool

Elapsed time was 36445 ms.
StringTable statistics:
Number of buckets       :     60013 =    480104 bytes, avg   8.000
Number of entries       :  10000767 = 240018408 bytes, avg  24.000
Number of literals      :  10000767 = 559972272 bytes, avg  55.993
Total footprint         :           = 800470784 bytes
Average bucket size     :   166.643
Variance of bucket size :    55.342
Std. dev. of bucket size:     7.439
Maximum bucket size     :       196

The more the string pool bucket list is full the less efficient your applicatioon would be. Because the comparison whether a string is there in the relevemt bucket list will be too high; 

To enhance the performnece of your application you can increase te default string pool size by the below command
@@@@@@@@@@@@@@@@
-XX:StringTableSize=120121 (this is the next prime number after the default one which is 60013) 

Elapsed time was 20445 ms.
StringTable statistics:
Number of buckets       :    120121 =    960968 bytes, avg   8.000
Number of entries       :  10000767 = 240018408 bytes, avg  24.000
Number of literals      :  10000767 = 559972272 bytes, avg  55.993
Total footprint         :           = 800951648 bytes
Average bucket size     :    83.256
Variance of bucket size :   492.378
Std. dev. of bucket size:    22.190
Maximum bucket size     :       157

You can notice now the Average bucket size reduced. And the time taken to perform the same operation. And if you notice the footprint, adding this flag have not added much overhead.

~~~ Tuning the size of the heap
-XX:+UnlockDiagnosticVMOptions -XX:+PrintFlagsFinal // to see the default values of the heap

InitialHeapSize                          := 268435456 (approax 260 MB)     
MaxHeapSize                              := 4267704320 (4GB)

-XX:MaxHeapSize=600m [SC: -Xmx600m]// to set the size of heap memory
Usualy the prefered way to test you aplication running efficiently use this flag to reduce the size.

-XX:InitialHeapSize=1g [SC: -Xms1g]// you can set the initial heap size to increase performace
// So once you got the base footprint of you application running, you can use these 2 flags to test your application performance. 
 
~~~~ GARBAGE COLLECTION 

Any object on the heap which cannot be reached through a reference from the stack is "eligible for garbage collection"
System.gc() - calling this method will explicitly telling JVM to freed up unused memory at that point. But calling this method expliciltly in a program is not a good idea. As running GC might halt you running program for sometime as that is going to freed up spaces. And there is not right place to call this. So the best way to handle GC is to let JVM handle that.

Finalize: From java 9 finalize() method is deprecated. As this can do some serious damage. So please look in to the java example we have created, where we created lotss of customers and in the customer class we override the finalize() method. We can see once we start explicitly the GC not all the customer is garbaged. More than that we can introduce some never ending loop to hang the GC process which will failed to freed up any un used memory and as a result you application can crash or performance will degrade.


~~~ Monitoring the HEAP

we can use one tool bundled in java called VisualVM to monitor the heap and metaspace is used for any running application. The exercise we have tried have seen how the program crashed in sometime and the same can be visualized in VisualVM heap. Later we fixed the problem in our code and ensured the heap size never crashed and we made our application more optimized.

~~~ Analyzing heap dump
@@@@@@@@@@@@@@@@
-XX:+HeapDumpOnOutOfMemoryError // it will dump the contents of a heap in case of any out of memory occurs
-XX:HeapDumpPath=someFilePath // store the dump file

Eclipse has one plugin Memory Analyzer(MAT) which actually helps to visulize the heap dump logs and let you easily figured it out what is the actual issue is.

~~~ Generational Garbage Collection

The Mark and Sweap process: This is a general algortihm that GC used. Instead of what are the objects is not in used GC look for all of the objects which need to be retain and then rescues them. So this is a two steps process. First step is the marking and second step is the sweaping. During MArking process all the threads of an running application are paused and marking will not work eficiently while there are running threads. The GC then checks all the live object refs. All the unmarked object are removed. Once the marking process done all the marked objects are then moved to a single contiguous block of memory. This stops to heap to become fragmented over time and make the easier and quicker for the virtual machine to find memory to allocate for future objects. 

So the GC actually does not collect and garbage it actually collects objects which are not eligible for garbage collection and it saves them. SO it means when there are many garbage the GC process will be pretty much instantaneous.

The problem with the above algorithm is suppose if we have many used references then the main app will hault for few seconds at a time as the GC will run to find out the live references. To avoid this we have something called Generational Garbage Collection. For this process Heap is actually organized into a separate sections.

Heap is divided into 2 sections (young gen and old gen). The young gen is much smalller compare to old gen. 
Then concept behind young and old generation is, all the new object creations take place in the young generations. And as this is the section where all the new objects will be stored so most of the object might are garbage and can quickly removed. So in this process the appliacation hault issue wont come. As young gen is smaller then running GC will be very quick compare to whole heap.
So once the objects survived one GC process those will be moved to old generation. And GC will take place in the old gen once the old gen memory is full or about to full.

The garbage collection of young gen is called Minor collection and the garbage collection of old generation called major collection. Major collection is usually slow process ad there can be huge objects to be fragment along with the check whether the object is still alive. So this process can hault the process but compare to earlier approach its very minimul.

The young gen is further divided into 3 sections.
EDEN
S0 - Survivor Space 0
S1 - Survivor Space 1

So when any new obejct created its placed in the eden space. When the eden space gets full then GC process would take place on the eden space and any surviving object gets moved to S0. Our application will then continue running and new objects gets created in the eden space. In the next GC process now it will scan eden space and S0 section and if any surviving object that gets moved to S1 and S0 and Eden gets empty. So in the next process the objects gets moved from eden and S1 to S0.  So S0 and S1 spaces is used in alternative way. At any point of time either of the Survivor space will be empty always. Thats why in the heap monitoring section we have seen there always some space in the heap which is not used though the heap memory gets full. This is beause of this survivor space.

So any object moving from S0 to S1 or S1 to S0 called one genaretion old. So suppose if any obejct moved from either of the survivor 5 times that means that object is 5 generation old. This is a threashold we can set that before moving to old gen, how many times those object has to be survive. 

Plugin can be installed in VisualVM name Visual GC to see these heap generation details.


~~~ Garbage Collector tuning & selection

@@@@@@@@@@@@@@@@
-verbose:gc //flag to see how often gc process take place while your app is running

while running with this flag in the output you can see 
GC (Allocation Failure)
Full GC 

So here GC means minor garbage collection and Full GC means Major.

When any application running JVM dynamically change the size of the Eden and both the survivors according to the neccessity. This can be switched off using the below command
@@@@@@@@@@@@@@@@
-XX:-UseAdaptiveSizePolicy 

By default this will be enabled.

@@@@@@@@@@@@@@@@
-XX:NewRatio=n // how many time bigger the old gen should be compare to young gen; default value is 2(this will vary machine to machine). That means old gen is 2 times bigger then young gen.

@@@@@@@@@@@@@@@@
-XX:SurvivorRatio=n //this falg means how much of the young gen should be taken up by the survivor spaces S0 and S1, the rest of this would be eden space.; default value is 8(this will vary machine to machine); This means S0 and S1 each will be 1/8 of the young generation, so eden space will be 6/8.

@@@@@@@@@@@@@@@@
-XX:MaxTenuringThreshold=n // this flag means how many generations should a object survive beofre become part of the old gen. Default value is 15(this will vary machine to machine). So 15 is the maximum value set. So JVM can take a decission to move the objects to old gen based on the optimizations. Dont set this value to more then 15, setting value 16 means obejcts will be forever resides in young gen and never go to old gen. So some java will allow youto set the value to 16 but the recommendation is dont.


~~~ Choosing Garbage Collectors

Types of collector:
- Serial: Serial means all the gc process will take part in a single thread. So when GC runs all your application threads will pause irrespective of how many threads your app runs.
@@@@@@@@@@@@@@@@
-XX:+UseSerialGC

- Parallel: GC process take place in a parallel threads. The performace is better then the serial. In java 8 this is the defalut GC collector set.
@@@@@@@@@@@@@@@@
-XX:+UseParallelGC

- Mostly Concurrent: GC process take place concurrently. That means its real time and while the process took place the application will not halt.
@@@@@@@@@@@@@@@@
-XX:+UseConcMarkSweepGC // java 9 this is default collector
-XX:+UseG1GC // java 10 this is default collector


~~~ Using a profiler to analyse application performance

JMC: Java Mission Control is an opensource tool which can help you to monitor all the important details of your running application including all the threads, heap memories, CPU usages and so on. JMC allowed you to record any statistics of your interests which propbaly will help you if your system got crash or anything. This will maintain the history of your given statistics which you can later analysis.

To enable flight record mode you have to pass below jvm arguments

@@@@@@@@@@@@@@@@
-XX:+UnlockCommercialFeatures
-XX:+FlightRecorder

Using JMC you can start recording but if you want to start reording from you application you have tp pass the below args
@@@@@@@@@@@@@@@@
-XX:StartFlightRecording=delay=2min, duration=60s,name=Test,filename=recording.jfr,settings=profile.

JMC allows you to drill down the problems in your aplication and give suggessions is possible to improve your code.











 


